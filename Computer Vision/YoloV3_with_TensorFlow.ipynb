{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mralamdari/ComputerVision_with_ImageProcessing/blob/main/YoloV3_with_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0qlttAELlC9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import PIL\n",
        "import colorsys\n",
        "import scipy.io\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tensorflow.python.saved_model import tag_constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hStuvGiBMSja"
      },
      "outputs": [],
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/MyDrive'\n",
        "!kaggle datasets download -d aruchomu/data-for-yolo-v3-kernel\n",
        "!unzip \\*.zip && rm *.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTSIBwjdMX5v"
      },
      "source": [
        "# Load The Yolo Model\n",
        "\n",
        "choose between yolo frameworks between; tf and trt\n",
        "\n",
        "\n",
        "and yolo types between;\n",
        "yolov3\n",
        "yolov3-tiny\n",
        "yolov4\n",
        "yolov4-tiny\n",
        "\n",
        "\n",
        " and decide if you need custom weights "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sG_4jEUNMZNh"
      },
      "outputs": [],
      "source": [
        "def load_yolo_model(yolo_costom_weights, input_size, input_classes, class_names):\n",
        "    \n",
        "    physical_devices = tf.config.list_physical_devices('GPU')\n",
        "    try:\n",
        "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    if yolo_costom_weights:\n",
        "        checkpoint = f\"./checkpoints/yolov3_custom\"\n",
        "        print(f\"Loading custom weights from: {checkpoint}\")\n",
        "        yolo = create_yolo_model(class_names, input_size=input_size, classes=input_classes)\n",
        "        yolo.load_weights(checkpoint)\n",
        "    else:\n",
        "        Darknet_weights = f'model_data/yolov3.weights'\n",
        "        print(f\"Loading Darknet_weights from: {Darknet_weights}\")\n",
        "        yolo = create_yolo_model(class_names, input_size=input_size, classes=input_classes)\n",
        "        load_yolo_weights(yolo, Darknet_weights) # use Darknet weights\n",
        "        \n",
        "    return yolo          "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkP7insYr0Q9"
      },
      "source": [
        "# Load The Yolo Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_JmdmirrvrC"
      },
      "outputs": [],
      "source": [
        "def load_yolo_weights(model, weights_file):\n",
        "    tf.keras.backend.clear_session() # used to reset layer names\n",
        "    range1 = 75\n",
        "    range2 = [58, 66, 74]\n",
        "    \n",
        "    with open(weights_file, 'rb') as wf:\n",
        "        major, minor, revision, seen, _ = np.fromfile(wf, dtype=np.int32, count=5)\n",
        "\n",
        "        j = 0\n",
        "        for i in range(range1):\n",
        "            conv_layer_name = 'conv2d' if i == 0 else f'conv2d_{i}'\n",
        "            bn_layer_name   = 'batch_normalization' if j == 0 else f'batch_normalization_{j}'\n",
        "            \n",
        "            conv_layer = model.get_layer(conv_layer_name)\n",
        "            \n",
        "            filters = conv_layer.filters\n",
        "            k_size = conv_layer.kernel_size[0]\n",
        "            in_dim = conv_layer.input_shape[-1]\n",
        "\n",
        "            if i not in range2:\n",
        "                # darknet weights: [beta, gamma, mean, variance]\n",
        "                bn_weights = np.fromfile(wf, dtype=np.float32, count=4 * filters)\n",
        "                # tf weights: [gamma, beta, mean, variance]\n",
        "                bn_weights = bn_weights.reshape((4, filters))[[1, 0, 2, 3]]\n",
        "                bn_layer = model.get_layer(bn_layer_name)\n",
        "                j += 1\n",
        "            else:\n",
        "                conv_bias = np.fromfile(wf, dtype=np.float32, count=filters)\n",
        "\n",
        "            # darknet shape (out_dim, in_dim, height, width)\n",
        "            conv_shape = (filters, in_dim, k_size, k_size)\n",
        "            # filters * in_dim * k_size * k_size\n",
        "            conv_count = np.product(conv_shape)    \n",
        "            conv_weights = np.fromfile(wf, dtype=np.float32, count=conv_count)\n",
        "            # tf shape (height, width, in_dim, out_dim)\n",
        "            conv_weights = conv_weights.reshape(conv_shape).transpose([2, 3, 1, 0])\n",
        "            # conv_weights = conv_weights.reshape(conv_shape[::-1])  # why this doesn't works?\n",
        "\n",
        "\n",
        "            if i not in range2:\n",
        "                conv_layer.set_weights([conv_weights])\n",
        "                bn_layer.set_weights(bn_weights)\n",
        "            else:\n",
        "                conv_layer.set_weights([conv_weights, conv_bias])\n",
        "\n",
        "        assert len(wf.read()) == 0, 'failed to read all data'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Boa4t2WNSS7"
      },
      "source": [
        "# Create Yolo Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RR6_TxpcNVCp"
      },
      "outputs": [],
      "source": [
        "def create_yolo_model(class_names, classes, input_size=416, channels=3, training=False):\n",
        "    \n",
        "    num_classes = len(class_names)\n",
        "    input_layer  = tf.keras.layers.Input([input_size, input_size, channels])  \n",
        "\n",
        "    yolo_anchors  = [[[10,  13], [16,   30], [33,   23]],\n",
        "                      [[30,  61], [62,   45], [59,  119]],\n",
        "                      [[116, 90], [156, 198], [373, 326]]] \n",
        "    convolutional_layers = YOLOv3(input_layer, num_classes)\n",
        "\n",
        "\n",
        "    anchors = (np.array(yolo_anchors).T / strides).T\n",
        "    output_tensors = []\n",
        "    for i, conv_layer in enumerate(convolutional_layers):\n",
        "        pred_tensor = decode(conv_layer, num_classes, i, strides, anchors)\n",
        "\n",
        "        \n",
        "        if training: \n",
        "          output_tensors.append(conv_layer)\n",
        "        \n",
        "        output_tensors.append(pred_tensor)\n",
        "\n",
        "    Yolo = tf.keras.Model(input_layer, output_tensors)\n",
        "\n",
        "    return Yolo    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xV-iOWU0NXgp"
      },
      "source": [
        "# Up Sample\n",
        "\n",
        "resize the batch of images' height and weidth\n",
        "\n",
        "    # shape=(None, 13, 13, 256)    ===>   (None, 26, 26, 256)\n",
        "    # shape=(None, 26, 26, 128)    ===>   (None, 56, 56, 128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTnP9K6zNXv2"
      },
      "outputs": [],
      "source": [
        "def upsample(input_layer):\n",
        "    return tf.keras.layers.UpSampling2D(2)(input_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMFUMkkxNz33"
      },
      "source": [
        "# Convolutional Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOQfi4XqN2Tj"
      },
      "outputs": [],
      "source": [
        "def convolutional(input_layer, input_dim, output_dim, kernel_size, downsample=False, activate=True, bn=True, activate_type='leaky'):\n",
        "    if downsample:\n",
        "        input_layer = tf.keras.layers.ZeroPadding2D(((1, 0), (1, 0)))(input_layer)\n",
        "        padding = 'valid'\n",
        "        strides = 2\n",
        "    else:\n",
        "        strides = 1\n",
        "        padding = 'same'\n",
        "\n",
        "    conv = tf.keras.layers.Conv2D(filters=output_dim,\n",
        "                                  kernel_size=kernel_size,\n",
        "                                  strides=strides,\n",
        "                                  padding=padding,\n",
        "                                  use_bias=not bn,\n",
        "                                  kernel_regularizer=tf.keras.regularizers.L2(0.0005),\n",
        "                                  kernel_initializer=tf.random_normal_initializer(stddev=0.01),\n",
        "                                  bias_initializer=tf.constant_initializer(0.))(input_layer)  \n",
        "\n",
        "    if bn: # BatchNormalization\n",
        "        conv = tf.keras.layers.BatchNormalization()(conv)\n",
        "    if activate == True: # Activation\n",
        "        if activate_type == \"leaky\":\n",
        "            conv = tf.keras.layers.LeakyReLU(alpha=0.1)(conv)\n",
        "        elif activate_type == \"mish\":\n",
        "          conv = tf.math.softplus(conv)\n",
        "          conv = conv * tf.math.tanh(conv)\n",
        "\n",
        "    return conv "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOPp6kF4N-iW"
      },
      "source": [
        "# Residual Block\n",
        "\n",
        "this blocks uses 2 convolutional layers with different kernels and filters, but at last, their output's and input's dimention are same so we can concatenate them and prevent the model from loosing the details in lower layers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leAucGvIN_Tl"
      },
      "outputs": [],
      "source": [
        "def residual_block(x, channels, filter1, filter2, activate_type='leaky'):\n",
        "    shortcut = x\n",
        "    x = convolutional(x, channels,filter1, 1, activate_type=activate_type)\n",
        "    x = convolutional(x, filter1, filter2, 3, activate_type=activate_type)\n",
        "\n",
        "    residual_layer = shortcut + x\n",
        "    return residual_layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlKh5ITE4Gpr"
      },
      "source": [
        "# Yolo V3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYO17crZ56a5"
      },
      "outputs": [],
      "source": [
        "!wget -P model_data https://pjreddie.com/media/files/yolov3.weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9CpBj_MIyRQ"
      },
      "source": [
        "## DarkNet 53\n",
        "\n",
        "it returns 3 branches to the yolo model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sL8cXdFz4ODO"
      },
      "outputs": [],
      "source": [
        "def darknet53(input_data):\n",
        "    input_data = convolutional(input_data, 3, 32, 3)\n",
        "    input_data = convolutional(input_data, 32, 64, 3, downsample=True)\n",
        "\n",
        "    for i in range(1):\n",
        "        input_data = residual_block(input_data,  64, 32, 64)\n",
        "\n",
        "    input_data = convolutional(input_data, 64, 128, 3, downsample=True)\n",
        "\n",
        "    for i in range(2):\n",
        "        input_data = residual_block(input_data, 128, 64, 128)\n",
        "\n",
        "    input_data = convolutional(input_data, 128, 256, 3, downsample=True)\n",
        "\n",
        "    for i in range(8):\n",
        "        input_data = residual_block(input_data, 256, 128, 256)\n",
        "\n",
        "    route_1 = input_data\n",
        "    input_data = convolutional(input_data, 256, 512, 3, downsample=True)\n",
        "\n",
        "    for i in range(8):\n",
        "        input_data = residual_block(input_data, 512, 256, 512)\n",
        "\n",
        "    route_2 = input_data\n",
        "    input_data = convolutional(input_data, 512, 1024, 3, downsample=True)\n",
        "\n",
        "    for i in range(4):\n",
        "        input_data = residual_block(input_data, 1024, 512, 1024)\n",
        "\n",
        "    return route_1, route_2, input_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fijLvIz9Jdn1"
      },
      "source": [
        "#### Yolov3 model it gets the results from the Darknet-53 bloack then predicts the pictures in 3 scales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6JopKdwIkOW"
      },
      "outputs": [],
      "source": [
        "def YOLOv3(input_layer, classes_count):\n",
        "    route_1, route_2, conv = darknet53(input_layer)\n",
        "\n",
        "    conv = convolutional(conv, 1024, 512, 1)\n",
        "    conv = convolutional(conv, 512, 1024, 3)\n",
        "    conv = convolutional(conv, 1024, 512, 1)\n",
        "    conv = convolutional(conv, 512, 1024, 3)\n",
        "    conv = convolutional(conv, 1024, 512, 1)\n",
        "    conv_lobj_branch = convolutional(conv, 512, 1024, 3)\n",
        "\n",
        "    # convolution_lbbox is used to predict large-sized objects , Shape = [None, 13, 13, 255]     \n",
        "    convolution_lbbox = convolutional(conv_lobj_branch, 1024, 3*(classes_count + 5), 1, activate_type=False, bn=False)\n",
        "\n",
        "    conv = convolutional(conv, 512,  256, 1)\n",
        "    # upsample here uses the \"nearest neighbor interpolation\" method, which has the advantage that the\n",
        "    # upsampling process does not need to learn, thereby reducing the network parameter  \n",
        "    conv = upsample(conv)\n",
        "\n",
        "    conv = tf.concat([conv, route_2], axis=-1)\n",
        "\n",
        "    conv = convolutional(conv, 768, 256, 1)\n",
        "    conv = convolutional(conv, 256, 512, 3)\n",
        "    conv = convolutional(conv, 512, 256, 1)\n",
        "    conv = convolutional(conv, 256, 512, 3)\n",
        "    conv = convolutional(conv, 512, 256, 1)\n",
        "    conv_mobj_branch = convolutional(conv, 256, 512, 3)\n",
        "\n",
        "    # convolution_mbbox is used to predict medium-sized objects, shape = [None, 26, 26, 255]\n",
        "    convolution_mbbox = convolutional(conv_mobj_branch, 512, 3*(classes_count + 5), 1, activate_type=False, bn=False)\n",
        "\n",
        "    conv = convolutional(conv, 256, 128, 1)\n",
        "    conv = upsample(conv)\n",
        "\n",
        "    conv = tf.concat([conv, route_1], axis=-1)\n",
        "    conv = convolutional(conv, 384, 128, 1)\n",
        "    conv = convolutional(conv, 128, 256, 3)\n",
        "    conv = convolutional(conv, 256, 128, 1)\n",
        "    conv = convolutional(conv, 128, 256, 3)\n",
        "    conv = convolutional(conv, 256, 128, 1)\n",
        "    conv_sobj_branch = convolutional(conv, 128, 256, 3)\n",
        "\n",
        "    # conv_sbbox is used to predict small size objects, shape = [None, 52, 52, 255]\n",
        "    conv_sbbox = convolutional(conv_sobj_branch, 256, 3*(classes_count +5), 1, activate_type=False, bn=False)\n",
        "        \n",
        "    return [conv_sbbox, convolution_mbbox, convolution_lbbox]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSgJtMxVF1an"
      },
      "source": [
        "# Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTqQry-YF3Fk"
      },
      "outputs": [],
      "source": [
        "def decode(conv_output, classes_count, i, strides, anchors):\n",
        "\n",
        "    # where i = 0, 1 or 2 to correspond to the three grid scales  \n",
        "    conv_shape       = tf.shape(conv_output)\n",
        "    batch_size       = conv_shape[0]\n",
        "    output_size      = conv_shape[1]\n",
        "\n",
        "    conv_output = tf.reshape(conv_output, (batch_size, output_size, output_size, 3, 5 + classes_count))\n",
        "    conv_raw_dxdy, conv_raw_dwdh, conv_raw_conf, conv_raw_prob = tf.split(conv_output, (2, 2, 1, classes_count), axis=-1)\n",
        "\n",
        "    xy_grid = tf.meshgrid(tf.range(output_size), tf.range(output_size))\n",
        "    xy_grid = tf.expand_dims(tf.stack(xy_grid, axis=-1), axis=2)  # [gx, gy, 1, 2]\n",
        "    xy_grid = tf.tile(tf.expand_dims(xy_grid, axis=0), [batch_size, 1, 1, 3, 1])\n",
        "    xy_grid = tf.cast(xy_grid, tf.float32)\n",
        "    \n",
        "    # Calculate the center position of the prediction box:\n",
        "    pred_xy = (tf.sigmoid(conv_raw_dxdy) + xy_grid) * strides[i]\n",
        "    # Calculate the length and width of the prediction box:\n",
        "    pred_wh = (tf.exp(conv_raw_dwdh) * anchors[i]) * strides[i]\n",
        "\n",
        "    pred_xywh = tf.concat([pred_xy, pred_wh], axis=-1)\n",
        "    pred_conf = tf.sigmoid(conv_raw_conf) # object box calculates the predicted confidence\n",
        "    pred_prob = tf.sigmoid(conv_raw_prob) # calculating the predicted probability category box object\n",
        "\n",
        "    # calculating the predicted probability category box object\n",
        "    return tf.concat([pred_xywh, pred_conf, pred_prob], axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dh3_8gUWqO3N"
      },
      "outputs": [],
      "source": [
        "def detect_image(input_type, Yolo, image_path, class_names,classes, input_size=416, show=False, score_threshold=0.3, iou_threshold=0.45, rectangle_colors='', yolo_framework='tf'):\n",
        "    if input_type == 'image':\n",
        "      original_image      = cv2.imread(image_path)\n",
        "      original_image      = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
        "      original_image      = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "      image_data = image_preprocess(np.copy(original_image), [input_size, input_size])\n",
        "      image_data = np.expand_dims(image_data, 0).astype(np.float32)\n",
        "\n",
        "\n",
        "      if yolo_framework == \"tf\":\n",
        "          pred_bbox = Yolo.predict(image_data)\n",
        "      elif yolo_framework == \"trt\":\n",
        "          batched_input = tf.constant(image_data)\n",
        "          result = Yolo(batched_input)\n",
        "          pred_bbox = []\n",
        "          for key, value in result.items():\n",
        "              value = value.numpy()\n",
        "              pred_bbox.append(value)\n",
        "\n",
        "      pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred_bbox]\n",
        "      pred_bbox = tf.concat(pred_bbox, axis=0)\n",
        "      \n",
        "      bboxes = postprocess_boxes(pred_bbox, original_image, input_size, score_threshold)\n",
        "      bboxes = nms(bboxes, iou_threshold, method='nms')\n",
        "\n",
        "      image = draw_bbox(original_image, bboxes, class_names, classes=classes, rectangle_colors=rectangle_colors)\n",
        "\n",
        "      output_path = f'{image_path[:-4]}_pred.jpg'\n",
        "      cv2.imwrite(output_path, image)\n",
        "      if show:\n",
        "          cv2.imshow('', image)\n",
        "          cv2.waitKey(0)\n",
        "          cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "    elif input_type == 'video':\n",
        "      win_name = 'Video Detection'\n",
        "      cap = cv2.VideoCapture(image_path)\n",
        "      frame_size = (cap.get(cv2.CAP_PROP_FRAME_WIDTH), cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "      fourcc = cv2.VideoWriter_fourcc(*'X264')\n",
        "      fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "      out = cv2.VideoWriter('/results.gif', fourcc, fps, (int(frame_size[0]), int(frame_size[1])))\n",
        "      while True:\n",
        "        ret, fram = cap.read()\n",
        "        if not ret:\n",
        "          break\n",
        "\n",
        "        original_image = fram\n",
        "\n",
        "        image_data = image_preprocess(np.copy(original_image), [input_size, input_size])\n",
        "        image_data = np.expand_dims(image_data, 0).astype(np.float32)\n",
        "\n",
        "        pred_bbox = Yolo.predict(image_data)\n",
        "        \n",
        "        pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred_bbox]\n",
        "        pred_bbox = tf.concat(pred_bbox, axis=0)\n",
        "        \n",
        "        bboxes = postprocess_boxes(pred_bbox, original_image, input_size, score_threshold)\n",
        "        bboxes = nms(bboxes, iou_threshold, method='nms')\n",
        "\n",
        "        image = draw_bbox(original_image, bboxes, class_names, classes=classes, rectangle_colors=rectangle_colors)\n",
        "        cv2.imshow('', image)\n",
        "        out.write(image)\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "      cv2.destroyAllWindows()\n",
        "      out.release()\n",
        "      cap.release()\n",
        "\n",
        "      \n",
        "    elif input_type == 'webcam':\n",
        "      win_name = 'WebCam Detection'\n",
        "      cap = cv2.VideoCapture(1)\n",
        "      frame_size = (cap.get(cv2.CAP_PROP_FRAME_WIDTH), cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "      fourcc = cv2.VideoWriter_fourcc(*'X264')\n",
        "      fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "      out = cv2.VideoWriter('/webcam_results.mp4', fourcc, fps, (int(frame_size[0]), int(frame_size[1])))\n",
        "      while True:\n",
        "        ret, fram = cap.read()\n",
        "        if not ret:\n",
        "          break\n",
        "\n",
        "        original_image = fram\n",
        "        image_data = image_preprocess(np.copy(original_image), [input_size, input_size])\n",
        "        image_data = np.expand_dims(image_data, 0).astype(np.float32)\n",
        "\n",
        "        pred_bbox = Yolo.predict(image_data)\n",
        "        \n",
        "        pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred_bbox]\n",
        "        pred_bbox = tf.concat(pred_bbox, axis=0)\n",
        "        \n",
        "        bboxes = postprocess_boxes(pred_bbox, original_image, input_size, score_threshold)\n",
        "        bboxes = nms(bboxes, iou_threshold, method='nms')\n",
        "\n",
        "        image = draw_bbox(original_image, bboxes, class_names, classes=classes, rectangle_colors=rectangle_colors)\n",
        "        \n",
        "        cv2.imshow('', image)\n",
        "        out.write(image)\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "    cv2.destroyAllWindows()\n",
        "    out.release()\n",
        "    cap.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7yKhsLTqTHt"
      },
      "outputs": [],
      "source": [
        "def image_preprocess(image, target_size, gt_boxes=None):\n",
        "    target_height, target_width  = target_size\n",
        "    h,  w, _  = image.shape\n",
        "\n",
        "    scale = min(target_width / w, target_height / h)\n",
        "    scaled_width, scaled_height  = int(scale * w), int(scale * h)\n",
        "\n",
        "    image_resized = cv2.resize(image, (scaled_width, scaled_height))\n",
        "    \n",
        "    image_paded = np.full(shape=[target_height, target_width, 3], fill_value=127.5)# fill_value = 255/2 == 127.5\n",
        "\n",
        "    offset_width, offset_height = (target_width - scaled_width) // 2, (target_height - scaled_height) // 2\n",
        "\n",
        "    image_paded[offset_height : scaled_height+offset_height, offset_width : scaled_width+offset_width, :] = image_resized\n",
        "    \n",
        "    image_paded = image_paded / 255.\n",
        "\n",
        "    if gt_boxes is None:\n",
        "        return image_paded\n",
        "\n",
        "    else:\n",
        "        gt_boxes[:, [0, 2]] = gt_boxes[:, [0, 2]] * scale + offset_width\n",
        "        gt_boxes[:, [1, 3]] = gt_boxes[:, [1, 3]] * scale + offset_height\n",
        "        return image_paded, gt_boxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ago8bUMXqWG0"
      },
      "outputs": [],
      "source": [
        "def postprocess_boxes(pred_bbox, original_image, input_size, score_threshold):\n",
        "    valid_scale=[0, np.inf]\n",
        "    pred_bbox = np.array(pred_bbox)\n",
        "\n",
        "    pred_xywh = pred_bbox[:, 0:4]\n",
        "    pred_conf = pred_bbox[:, 4]\n",
        "    pred_prob = pred_bbox[:, 5:]\n",
        "\n",
        "\n",
        "    # 1. (x, y, w, h) --> (xmin, ymin, xmax, ymax)\n",
        "    pred_coor = np.concatenate([pred_xywh[:, :2] - pred_xywh[:, 2:] * 0.5,\n",
        "                                pred_xywh[:, :2] + pred_xywh[:, 2:] * 0.5], axis=-1)\n",
        "    \n",
        "    \n",
        "    # 2. (xmin, ymin, xmax, ymax) -> (xmin_org, ymin_org, xmax_org, ymax_org)\n",
        "    org_h, org_w = original_image.shape[:2]\n",
        "    resize_ratio = min(input_size / org_w, input_size / org_h)\n",
        "\n",
        "    dw = (input_size - resize_ratio * org_w) / 2\n",
        "    dh = (input_size - resize_ratio * org_h) / 2\n",
        "\n",
        "#  pred_coor[:, 1::2] strart from 1 and jump indexis 2 by 2\n",
        "\n",
        "    pred_coor[:, 0::2] = (pred_coor[:, 0::2] - dw) / resize_ratio   #X, W\n",
        "    pred_coor[:, 1::2] = (pred_coor[:, 1::2] - dh) / resize_ratio   #Y, H\n",
        "    # 3. clip some boxes those are out of range\n",
        "    pred_coor = np.concatenate([np.maximum(pred_coor[:, :2], [0, 0]),\n",
        "                                np.minimum(pred_coor[:, 2:], [org_w - 1, org_h - 1])], axis=-1)\n",
        "    invalid_mask = np.logical_or((pred_coor[:, 0] > pred_coor[:, 2]), (pred_coor[:, 1] > pred_coor[:, 3]))  # x>w or y>h\n",
        "    pred_coor[invalid_mask] = 0\n",
        "\n",
        "    # 4. discard some invalid boxes\n",
        "    bboxes_scale = np.sqrt(np.multiply.reduce(pred_coor[:, 2:4] - pred_coor[:, 0:2], axis=-1))\n",
        "    scale_mask = np.logical_and((valid_scale[0] < bboxes_scale), (bboxes_scale < valid_scale[1]))\n",
        "\n",
        "    # 5. discard boxes with low scores\n",
        "    classes = np.argmax(pred_prob, axis=-1)\n",
        "    scores = pred_conf * pred_prob[np.arange(len(pred_coor)), classes]\n",
        "    # scores = pred_conf * pred_prob[:, classes]\n",
        "\n",
        "    score_mask = scores > score_threshold\n",
        "    mask = np.logical_and(scale_mask, score_mask)\n",
        "    coors, scores, classes = pred_coor[mask], scores[mask], classes[mask]\n",
        "    return np.concatenate([coors, scores[:, np.newaxis], classes[:, np.newaxis]], axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9sOqq93qW0l"
      },
      "outputs": [],
      "source": [
        "def draw_bbox(image, bboxes, class_names, classes, show_label=True, show_confidence = True, Text_colors=(255,255,0), rectangle_colors='', tracking=False):   \n",
        "    num_classes = len(class_names)\n",
        "    image_h, image_w, _ = image.shape\n",
        "    hsv_tuples = [(1.0 * x / num_classes, 1., 1.) for x in range(num_classes)]\n",
        "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
        "    colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors))\n",
        "\n",
        "    np.random.seed(0)\n",
        "    np.random.shuffle(colors)\n",
        "    np.random.seed(None)\n",
        "\n",
        "    for i, bbox in enumerate(bboxes):\n",
        "        coor = np.array(bbox[:4], dtype=np.int32)\n",
        "        score = bbox[4]\n",
        "        class_ind = int(bbox[5])\n",
        "        bbox_color = rectangle_colors if rectangle_colors != '' else colors[class_ind]\n",
        "        bbox_thick = int(0.6 * (image_h + image_w) / 1000)\n",
        "        if bbox_thick < 1: bbox_thick = 1\n",
        "        fontScale = 0.75 * bbox_thick\n",
        "        (x1, y1), (x2, y2) = (coor[0], coor[1]), (coor[2], coor[3])\n",
        "\n",
        "        # put object rectangle\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), bbox_color, bbox_thick*2)\n",
        "\n",
        "        if show_label:\n",
        "            # get text label\n",
        "            score_str = \" {:.3f}\".format(score) if show_confidence else \"\"\n",
        "\n",
        "            if tracking: score_str = \" \"+str(score)\n",
        "\n",
        "            try:\n",
        "                label = \"{}\".format(class_names[class_ind]) + score_str\n",
        "            except KeyError:\n",
        "                print(\"\"\"You received KeyError, this might be that you are trying to use yolo original weights,\n",
        "                while using custom classes, if using custom model in configs.py set YOLO_CUSTOM_WEIGHTS = True\"\"\")\n",
        "\n",
        "            # get text size\n",
        "            (text_width, text_height), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_COMPLEX_SMALL, fontScale, thickness=bbox_thick)\n",
        "            # put filled text rectangle\n",
        "            cv2.rectangle(image, (x1, y1), (x1 + text_width, y1 - text_height - baseline), bbox_color, thickness=cv2.FILLED)\n",
        "\n",
        "            # put text above rectangle\n",
        "            cv2.putText(image, label, (x1, y1-4), cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
        "                        fontScale, Text_colors, bbox_thick, lineType=cv2.LINE_AA)\n",
        "\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-j20rVLxqab9"
      },
      "outputs": [],
      "source": [
        "def bboxes_iou(boxes1, boxes2):\n",
        "    boxes1 = np.array(boxes1)\n",
        "    boxes2 = np.array(boxes2)\n",
        "\n",
        "    boxes1_area = (boxes1[..., 2] - boxes1[..., 0]) * (boxes1[..., 3] - boxes1[..., 1])\n",
        "    boxes2_area = (boxes2[..., 2] - boxes2[..., 0]) * (boxes2[..., 3] - boxes2[..., 1])\n",
        "    left_up       = np.maximum(boxes1[..., :2], boxes2[..., :2])\n",
        "    right_down    = np.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
        "\n",
        "    inter_section = np.maximum(right_down - left_up, 0.0)\n",
        "    inter_area    = inter_section[..., 0] * inter_section[..., 1]\n",
        "    union_area    = boxes1_area + boxes2_area - inter_area\n",
        "    ious          = np.maximum(1.0 * inter_area / union_area, np.finfo(np.float32).eps)\n",
        "\n",
        "    return ious"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrHBF19vqcmw"
      },
      "outputs": [],
      "source": [
        "def nms(bboxes, iou_threshold, sigma=0.3, method='nms'):\n",
        "    \"\"\"\n",
        "    :param bboxes: (xmin, ymin, xmax, ymax, score, class)\n",
        "    Note: soft-nms, https://arxiv.org/pdf/1704.04503.pdf\n",
        "          https://github.com/bharatsingh430/soft-nms\n",
        "    \"\"\"\n",
        "    classes_in_img = list(set(bboxes[:, 5]))\n",
        "    best_bboxes = []\n",
        "    for cls in classes_in_img:\n",
        "        cls_mask = (bboxes[:, 5] == cls)\n",
        "        cls_bboxes = bboxes[cls_mask]\n",
        "        # Process 1: Determine whether the number of bounding boxes is greater than 0 \n",
        "        while len(cls_bboxes) > 0:\n",
        "            # Process 2: Select the bounding box with the highest score according to score order A\n",
        "            max_ind = np.argmax(cls_bboxes[:, 4])\n",
        "            best_bbox = cls_bboxes[max_ind]\n",
        "            best_bboxes.append(best_bbox)\n",
        "            cls_bboxes = np.concatenate([cls_bboxes[: max_ind], cls_bboxes[max_ind + 1:]])\n",
        "            # Process 3: Calculate this bounding box A and\n",
        "            # Remain all iou of the bounding box and remove those bounding boxes whose iou value is higher than the threshold \n",
        "            iou = bboxes_iou(best_bbox[np.newaxis, :4], cls_bboxes[:, :4])\n",
        "            weight = np.ones((len(iou),), dtype=np.float32)\n",
        "\n",
        "            assert method in ['nms', 'soft-nms']\n",
        "\n",
        "            if method == 'nms':\n",
        "                iou_mask = iou > iou_threshold\n",
        "                weight[iou_mask] = 0.0\n",
        "\n",
        "            if method == 'soft-nms':\n",
        "                weight = np.exp(-(1.0 * iou ** 2 / sigma))\n",
        "\n",
        "            cls_bboxes[:, 4] = cls_bboxes[:, 4] * weight\n",
        "            score_mask = cls_bboxes[:, 4] > 0.\n",
        "            cls_bboxes = cls_bboxes[score_mask]\n",
        "\n",
        "    return best_bboxes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhduHHMu78Zf"
      },
      "source": [
        "#Boxes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://media.giphy.com/media/oO5a8cQSmxb3b1TBRu/giphy.gif"
      ],
      "metadata": {
        "id": "L6gh1Rp4vFoe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a91043df-6c4c-4e40-e6dd-6ac2dcd6385b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-22 13:49:27--  https://media.giphy.com/media/oO5a8cQSmxb3b1TBRu/giphy.gif\n",
            "Resolving media.giphy.com (media.giphy.com)... 199.232.194.2, 199.232.198.2\n",
            "Connecting to media.giphy.com (media.giphy.com)|199.232.194.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1349105 (1.3M) [image/gif]\n",
            "Saving to: ‘giphy.gif’\n",
            "\n",
            "giphy.gif           100%[===================>]   1.29M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2022-08-22 13:49:27 (24.0 MB/s) - ‘giphy.gif’ saved [1349105/1349105]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UdBcAxOOCyQ",
        "outputId": "2a0b7ced-8527-4d06-905f-19a92c80a725"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Darknet_weights from: model_data/yolov3.weights\n"
          ]
        }
      ],
      "source": [
        "# input_classes     ====> 'mnist/mnist.names', '/content/coco.names'\n",
        "\n",
        "input_classes=\"/content/coco.names\"\n",
        "\n",
        "class_names = {}\n",
        "with open(input_classes, 'r') as data:\n",
        "    for ID, name in enumerate(data):\n",
        "        class_names[ID] = name.strip('\\n')\n",
        "\n",
        "yolo = load_yolo_model(yolo_costom_weights=False,\n",
        "                       input_size=416,\n",
        "                       input_classes=input_classes, \n",
        "                       class_names=class_names)\n",
        "\n",
        "image_path = '/content/dog.jpg'\n",
        "image_path = '/content/office.jpg'\n",
        "gif_path   = '/content/giphy.gif' \n",
        "\n",
        "# input_type = 'image', 'webcam', 'video'\n",
        "input_type = 'webcam'\n",
        "\n",
        "\n",
        "detect_image(input_type,yolo, gif_path, class_names=class_names, classes = input_classes ,input_size=416, show=True, rectangle_colors=(255,0,0))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "mount_file_id": "1D1wCzZ-nXxk98Y-65JDByRo15VKdZH0m",
      "authorship_tag": "ABX9TyPISRYUzxLcw5h/12+oeFX/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}